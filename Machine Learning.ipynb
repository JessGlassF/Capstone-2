{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "006d622d-b0cd-4587-bee3-7028249735f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "594c25cf-4f90-4571-b82d-dd3905692fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2909b97-119a-40e6-a99f-3488d8acdff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "file = 'encoded.csv'\n",
    "books_df= pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75f4cdc6-eb02-4c69-a9f4-e72be0e4552a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  book_id    rating\n",
      "0        1        0 -0.959559\n",
      "1        1        1  1.606694\n",
      "2        1        2  0.673511\n",
      "3        1        3 -0.155985\n",
      "4        1        4 -0.415203\n"
     ]
    }
   ],
   "source": [
    "books_df['book_id'] = range(len(books_df))\n",
    "books_df['user_id'] = 1\n",
    "print(books_df[['user_id', 'book_id', 'rating']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffd36ab6-7f8c-414d-a621-cb6e246eb5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title                 0\n",
      "author                0\n",
      "desc                  0\n",
      "genre                 0\n",
      "rating                0\n",
      "Languages             0\n",
      "Culture               0\n",
      "Mystery               0\n",
      "Non-Fiction           0\n",
      "Animals               0\n",
      "Travel                0\n",
      "Religion              0\n",
      "Social Issues         0\n",
      "Young Adult           0\n",
      "Unknown               0\n",
      "Politics              0\n",
      "Geography             0\n",
      "Science Fiction       0\n",
      "Lifestyle             0\n",
      "History               0\n",
      "Hobbies               0\n",
      "Fiction               0\n",
      "Science               0\n",
      "Action                0\n",
      "Academia              0\n",
      "Historical Fiction    0\n",
      "Fantasy               0\n",
      "Entertainment         0\n",
      "Romance               0\n",
      "Mythology             0\n",
      "Technology            0\n",
      "Education             0\n",
      "Art                   0\n",
      "book_id               0\n",
      "user_id               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(books_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d81c1d65-235e-47a4-9652-8a1559f7c6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_columns = [\n",
    "    'Languages', 'Culture', 'Mystery', 'Non-Fiction', 'Animals', 'Travel',\n",
    "    'Religion', 'Social Issues', 'Young Adult', 'Unknown', 'Politics',\n",
    "    'Geography', 'Science Fiction', 'Lifestyle', 'History', 'Hobbies',\n",
    "    'Fiction', 'Science', 'Action', 'Academia', 'Historical Fiction',\n",
    "    'Fantasy', 'Entertainment', 'Romance', 'Mythology', 'Technology',\n",
    "    'Education', 'Art'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67e71219-1dbe-444e-9e29-feb41b49d517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine genre columns into a list of genres per book\n",
    "books_df['genres'] = books_df[genre_columns].apply(lambda row: [genre for genre in genre_columns if row[genre] == 1], axis=1)\n",
    "\n",
    "# Initialize MultiLabelBinarizer to transform genre lists to binary matrix\n",
    "mlb = MultiLabelBinarizer()\n",
    "genres_encoded = mlb.fit_transform(books_df['genres'])\n",
    "genres_df = pd.DataFrame(genres_encoded, columns=mlb.classes_)\n",
    "\n",
    "# Combine with original DataFrame\n",
    "books_df = pd.concat([books_df, genres_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e358e8d5-881b-470c-b1d3-cb5d198c5cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = books_df[mlb.classes_].copy()\n",
    "features['rating'] = books_df['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff375a6a-acaa-423a-965f-6754373523bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 89521)\n"
     ]
    }
   ],
   "source": [
    "# Create user-item matrix\n",
    "user_item_matrix = books_df.pivot(index='user_id', columns='book_id', values='rating')\n",
    "\n",
    "print(user_item_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e324fff3-ab78-45ab-b898-7fe11ec4466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and rename duplicate columns\n",
    "def rename_duplicate_columns(df):\n",
    "    cols = pd.Series(df.columns)\n",
    "    for dup in cols[cols.duplicated()].unique(): \n",
    "        cols[cols[cols == dup].index.values.tolist()] = [dup + '_' + str(i) if i != 0 else dup for i in range(sum(cols == dup))]\n",
    "    df.columns = cols\n",
    "\n",
    "# Rename duplicate columns if any\n",
    "rename_duplicate_columns(books_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "756b0d7d-8fbd-4b9d-8574-4d464a25d5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply renaming\n",
    "rename_duplicate_columns(books_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "561be96c-6fa9-48e2-b811-95e929f604ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated DataFrame with simulated ratings:\n",
      "                                                    title  \\\n",
      "0       Between Two Fires: American Indians in the Civ...   \n",
      "1                                Fashion Sourcebook 1920s   \n",
      "2                                              Hungary 56   \n",
      "3       All-American Anarchist: Joseph A. Labadie and ...   \n",
      "4       The Human Equation: Building Profits by Puttin...   \n",
      "...                                                   ...   \n",
      "984726                                                NaN   \n",
      "984727                                                NaN   \n",
      "984728                                                NaN   \n",
      "984729                                                NaN   \n",
      "984730                                                NaN   \n",
      "\n",
      "                                  author  \\\n",
      "0                   Laurence M. Hauptman   \n",
      "1       Charlotte Fiell,Emmanuelle Dirix   \n",
      "2                          Andy Anderson   \n",
      "3                   Carlotta R. Anderson   \n",
      "4                        Jeffrey Pfeffer   \n",
      "...                                  ...   \n",
      "984726                               NaN   \n",
      "984727                               NaN   \n",
      "984728                               NaN   \n",
      "984729                               NaN   \n",
      "984730                               NaN   \n",
      "\n",
      "                                                     desc  \\\n",
      "0       Reveals that several hundred thousand Indians ...   \n",
      "1       Fashion Sourcebook - 1920s is the first book i...   \n",
      "2       The seminal history and analysis of the Hungar...   \n",
      "3       \"All-American Anarchist\" chronicles the life a...   \n",
      "4       Why is common sense so uncommon when it comes ...   \n",
      "...                                                   ...   \n",
      "984726                                                NaN   \n",
      "984727                                                NaN   \n",
      "984728                                                NaN   \n",
      "984729                                                NaN   \n",
      "984730                                                NaN   \n",
      "\n",
      "                                                    genre    rating  \\\n",
      "0       ['history', 'military', 'history', 'civil', 'w... -0.959559   \n",
      "1       ['couture', 'fashion', 'historical', 'art', 'n...  1.606694   \n",
      "2                                 ['politics', 'history']  0.673511   \n",
      "3                                    ['labor', 'history'] -0.155985   \n",
      "4       ['business', 'leadership', 'romance', 'histori... -0.415203   \n",
      "...                                                   ...       ...   \n",
      "984726                                                NaN  4.315255   \n",
      "984727                                                NaN  4.869222   \n",
      "984728                                                NaN  2.611831   \n",
      "984729                                                NaN  2.027238   \n",
      "984730                                                NaN  3.680690   \n",
      "\n",
      "        Languages  Culture  Mystery  Non-Fiction  Animals  ...  Politics_1  \\\n",
      "0             0.0      0.0      0.0          0.0      0.0  ...         1.0   \n",
      "1             0.0      0.0      0.0          0.0      0.0  ...         0.0   \n",
      "2             0.0      0.0      0.0          0.0      0.0  ...         1.0   \n",
      "3             0.0      0.0      0.0          0.0      0.0  ...         1.0   \n",
      "4             0.0      0.0      0.0          0.0      0.0  ...         0.0   \n",
      "...           ...      ...      ...          ...      ...  ...         ...   \n",
      "984726        NaN      NaN      NaN          NaN      NaN  ...         NaN   \n",
      "984727        NaN      NaN      NaN          NaN      NaN  ...         NaN   \n",
      "984728        NaN      NaN      NaN          NaN      NaN  ...         NaN   \n",
      "984729        NaN      NaN      NaN          NaN      NaN  ...         NaN   \n",
      "984730        NaN      NaN      NaN          NaN      NaN  ...         NaN   \n",
      "\n",
      "        Religion_1  Romance_1  Science_1  Science Fiction_1  Social Issues_1  \\\n",
      "0              0.0        0.0        0.0                0.0              0.0   \n",
      "1              0.0        0.0        0.0                0.0              0.0   \n",
      "2              0.0        0.0        0.0                0.0              0.0   \n",
      "3              0.0        0.0        0.0                0.0              0.0   \n",
      "4              0.0        0.0        0.0                0.0              0.0   \n",
      "...            ...        ...        ...                ...              ...   \n",
      "984726         NaN        NaN        NaN                NaN              NaN   \n",
      "984727         NaN        NaN        NaN                NaN              NaN   \n",
      "984728         NaN        NaN        NaN                NaN              NaN   \n",
      "984729         NaN        NaN        NaN                NaN              NaN   \n",
      "984730         NaN        NaN        NaN                NaN              NaN   \n",
      "\n",
      "        Technology_1  Travel_1  Unknown_1  Young Adult_1  \n",
      "0                0.0       0.0        1.0            0.0  \n",
      "1                0.0       0.0        1.0            0.0  \n",
      "2                0.0       0.0        1.0            0.0  \n",
      "3                0.0       0.0        1.0            0.0  \n",
      "4                0.0       0.0        1.0            0.0  \n",
      "...              ...       ...        ...            ...  \n",
      "984726           NaN       NaN        NaN            NaN  \n",
      "984727           NaN       NaN        NaN            NaN  \n",
      "984728           NaN       NaN        NaN            NaN  \n",
      "984729           NaN       NaN        NaN            NaN  \n",
      "984730           NaN       NaN        NaN            NaN  \n",
      "\n",
      "[984731 rows x 64 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Index contains duplicate entries, cannot reshape",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(books_df)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Create user-item matrix\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m user_item_matrix \u001b[38;5;241m=\u001b[39m books_df\u001b[38;5;241m.\u001b[39mpivot(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbook_id\u001b[39m\u001b[38;5;124m'\u001b[39m, values\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mUser-item matrix:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(user_item_matrix)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:9339\u001b[0m, in \u001b[0;36mDataFrame.pivot\u001b[1;34m(self, columns, index, values)\u001b[0m\n\u001b[0;32m   9332\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   9333\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpivot\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   9334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpivot\u001b[39m(\n\u001b[0;32m   9335\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, columns, index\u001b[38;5;241m=\u001b[39mlib\u001b[38;5;241m.\u001b[39mno_default, values\u001b[38;5;241m=\u001b[39mlib\u001b[38;5;241m.\u001b[39mno_default\n\u001b[0;32m   9336\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m   9337\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpivot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pivot\n\u001b[1;32m-> 9339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pivot(\u001b[38;5;28mself\u001b[39m, index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns, values\u001b[38;5;241m=\u001b[39mvalues)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\pivot.py:570\u001b[0m, in \u001b[0;36mpivot\u001b[1;34m(data, columns, index, values)\u001b[0m\n\u001b[0;32m    566\u001b[0m         indexed \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39m_constructor_sliced(data[values]\u001b[38;5;241m.\u001b[39m_values, index\u001b[38;5;241m=\u001b[39mmultiindex)\n\u001b[0;32m    567\u001b[0m \u001b[38;5;66;03m# error: Argument 1 to \"unstack\" of \"DataFrame\" has incompatible type \"Union\u001b[39;00m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;66;03m# [List[Any], ExtensionArray, ndarray[Any, Any], Index, Series]\"; expected\u001b[39;00m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;66;03m# \"Hashable\"\u001b[39;00m\n\u001b[1;32m--> 570\u001b[0m result \u001b[38;5;241m=\u001b[39m indexed\u001b[38;5;241m.\u001b[39munstack(columns_listlike)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    571\u001b[0m result\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mnames \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    572\u001b[0m     name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mnames\n\u001b[0;32m    573\u001b[0m ]\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4615\u001b[0m, in \u001b[0;36mSeries.unstack\u001b[1;34m(self, level, fill_value, sort)\u001b[0m\n\u001b[0;32m   4570\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4571\u001b[0m \u001b[38;5;124;03mUnstack, also known as pivot, Series with MultiIndex to produce DataFrame.\u001b[39;00m\n\u001b[0;32m   4572\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4611\u001b[0m \u001b[38;5;124;03mb    2    4\u001b[39;00m\n\u001b[0;32m   4612\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4613\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m unstack\n\u001b[1;32m-> 4615\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unstack(\u001b[38;5;28mself\u001b[39m, level, fill_value, sort)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\reshape.py:517\u001b[0m, in \u001b[0;36munstack\u001b[1;34m(obj, level, fill_value, sort)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_1d_only_ea_dtype(obj\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unstack_extension_series(obj, level, fill_value, sort\u001b[38;5;241m=\u001b[39msort)\n\u001b[1;32m--> 517\u001b[0m unstacker \u001b[38;5;241m=\u001b[39m _Unstacker(\n\u001b[0;32m    518\u001b[0m     obj\u001b[38;5;241m.\u001b[39mindex, level\u001b[38;5;241m=\u001b[39mlevel, constructor\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39m_constructor_expanddim, sort\u001b[38;5;241m=\u001b[39msort\n\u001b[0;32m    519\u001b[0m )\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unstacker\u001b[38;5;241m.\u001b[39mget_result(\n\u001b[0;32m    521\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_values, value_columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, fill_value\u001b[38;5;241m=\u001b[39mfill_value\n\u001b[0;32m    522\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\reshape.py:154\u001b[0m, in \u001b[0;36m_Unstacker.__init__\u001b[1;34m(self, index, level, constructor, sort)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_cells \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax:\n\u001b[0;32m    147\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following operation may generate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_cells\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cells \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min the resulting pandas object.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    150\u001b[0m         PerformanceWarning,\n\u001b[0;32m    151\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    152\u001b[0m     )\n\u001b[1;32m--> 154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_selectors()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\reshape.py:210\u001b[0m, in \u001b[0;36m_Unstacker._make_selectors\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    207\u001b[0m mask\u001b[38;5;241m.\u001b[39mput(selector, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex contains duplicate entries, cannot reshape\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_index \u001b[38;5;241m=\u001b[39m comp_index\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask \u001b[38;5;241m=\u001b[39m mask\n",
      "\u001b[1;31mValueError\u001b[0m: Index contains duplicate entries, cannot reshape"
     ]
    }
   ],
   "source": [
    "# Parameters for simulation\n",
    "num_simulated_users = 10  # Number of additional users\n",
    "num_simulated_books = len(books_df)  # Number of existing books\n",
    "\n",
    "# Generate simulated user ratings\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "# Simulated additional ratings\n",
    "additional_data = {\n",
    "    'user_id': np.random.randint(1, num_simulated_users + 1, size=num_simulated_books * num_simulated_users),\n",
    "    'book_id': np.tile(books_df['title'], num_simulated_users),\n",
    "    'rating': np.random.uniform(1, 5, size=num_simulated_books * num_simulated_users)\n",
    "}\n",
    "\n",
    "# Create DataFrame for simulated ratings\n",
    "additional_df = pd.DataFrame(additional_data)\n",
    "\n",
    "# Combine existing book data with simulated ratings\n",
    "# Assuming you want to keep the existing book data and add the ratings to it\n",
    "books_df = pd.concat([books_df, additional_df], ignore_index=True)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(\"Updated DataFrame with simulated ratings:\")\n",
    "print(books_df)\n",
    "\n",
    "# Create user-item matrix\n",
    "user_item_matrix = books_df.pivot(index='user_id', columns='book_id', values='rating')\n",
    "\n",
    "print(\"\\nUser-item matrix:\")\n",
    "print(user_item_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6621111-3792-4d1f-827e-41d2d7ae4ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Convert DataFrame into Surprise dataset\n",
    "reader = Reader(rating_scale=(books_df['rating'].min(), books_df['rating'].max()))\n",
    "data = Dataset.load_from_df(books_df[['user_id', 'book_id', 'rating']], reader)\n",
    "\n",
    "# Create train-test split using Surprise\n",
    "trainset, testset = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5c29f75-7ab1-4457-882a-f91543a2656f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 0.00%\n"
     ]
    }
   ],
   "source": [
    "sparsity = 1.0 - (np.count_nonzero(user_item_matrix) / float(user_item_matrix.size))\n",
    "print(f\"Sparsity: {sparsity:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd176456-0fed-4dee-af01-29fe3fe9313e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x1c190e9f8f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the SVD model\n",
    "model = SVD()\n",
    "model.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40bf5d6d-3b3c-4da1-8fb5-bd3d6521d270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.3243\n",
      "RMSE: 1.3243021853088448\n"
     ]
    }
   ],
   "source": [
    "predictions = model.test(testset)\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print(f'RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42f36245-b81f-4277-999c-8277c116c7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "def get_recommendations(user_id, model, user_item_matrix, top_n=10):\n",
    "    # Predict ratings for all books that the user hasn't rated\n",
    "    all_books = user_item_matrix.columns\n",
    "    rated_books = user_item_matrix.loc[user_id].dropna().index\n",
    "    unrated_books = [book for book in all_books if book not in rated_books]\n",
    "    \n",
    "    predictions = [model.predict(user_id, book) for book in unrated_books]\n",
    "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "    \n",
    "    top_recommendations = predictions[:top_n]\n",
    "    return [(pred.iid, pred.est) for pred in top_recommendations]\n",
    "\n",
    "# Example usage\n",
    "recommendations = get_recommendations(user_id=1, model=model, user_item_matrix=user_item_matrix)\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf81d54-7160-42a8-be6e-434666eed247",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
